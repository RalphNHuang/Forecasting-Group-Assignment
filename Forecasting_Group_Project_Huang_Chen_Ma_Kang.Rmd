---
title: "Forecasting Group Project"
author: "Yue Chen, Kai Kang, Jiaqian Ma, Yinzhe Huang"
date: "2022/1/1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r:}
source("./R/utils.R")
source("./R/dataUtils.R")
load("./RData/dataset.RData")
load("./RData/scaled_naive.RData")

library(fpp2)
library(smooth)



```

## 1 Assessing the data and univariate benchmarks
### 1.1 Are these six variables stationary,
#### (a) using a simple method, e.g. looking at the time series plots and at the ACF/PACF?
```{r: ACF&PACF}

```
#### (b) performing a test?

```{r: ADF test}

```
Based on the result of ADF test on each column, expect for p-value of `Foods_1_CA_2`, p-value of the rest column is less than 0.05, which means that the other 17 time series data is stationary. 
S
### 1.2 We now want to assess the set of benchmark in the M5 guidelines. For several sample splits of your choice,
#### (a) Fit Statistical benchmarks 1 (Naive), 2 (sNaive), 3 (ES), 4 (MA), 13 (ESX), as well
#### as SARIMA, SARIMAX (using X as in ESX) and Holt-Winters up to the end of the
#### training subsample.
#### (b) Consider also a state-space model where the latent state variable follows a random walk.
#### Have a look as well at the TBATS package in R.
#### (c) Obtain a sequence of 1-step ahead point forecasts over the testing subsample.
#### (d) Assess the quality of the forecasts using relevant loss functions.
#### (e) Compare the above with combinations of the forecasting techniques (using simple averages across methods, such as Combination benchmark #21 in the M5 guidelines).
#### (f) Compare the in-sample (training) vs. out-of-sample (testing) fit of the models.
#### (g) Do you find similarities in terms of forecast performance across stores or types of items?



### 1.3 Consider varying the horizon, h, and obtaining forecasts for h = 1, ..., 28. Do you find different
### rankings of models according to the RMSSE (Root Mean Square Scaled Error) suggested in
### the M5 guidelines.



### 1.4 Now, in this question only, aggregate the data at the store or type of item level.
#### (a) Produce forecasts for these aggregates using the previous methods and assess them.
#### (b) Compare the forecasts of the aggregates to the aggregates of the forecasts that you
#### had obtained in previous questions, can you find systematic pattern in terms of relative
#### forecasting performance?



### 1.5 Now, in this question only, aggregate the data at the weekly frequency,
#### (a) produce forecasts for the weekly aggregates using the previous methods and assess them
#### (b) Compare the forecasts of the weekly aggregates vs. the weekly aggregates of the daily
#### forecasts, can you find systematic pattern?



### 1.6 OPTIONAL: Based on your answers to questions 4 and 5 above, see whether using lags of
#### the aggregates can help forecasting the daily data. When using lags of temporal aggregates,
#### this is related to the HAR model à la Corsi (2009).1 You may want also to consider an
#### ARFIMA(p, d, q) model where d ∈ (0, 1).



### 1.7 We now only focus on forecasting the disaggregates (original data).
#### (a) Consider the probabilistic forecasts i to vi in the M5 guidelines
#### (b) Assess them using the Scaled Pinball Loss (p7 of the M5 guidelines).








## 2 Multivariate Models

### 2.1 Consider a VAR model for each store and obtain resulting forecasts for the testing sample



### 2.2 Consider a VAR model for each type of products and obtain forecasts.



### 2.3 Consider a large VAR model involving all variables.



### 2.4 OPTIONAL

#### (a) If you wish, you may consider dynamic factor models where you allow the possibility of
#### one factor for each store or each type of item.

#### (b) If you wish, you may use the whole dataset available on github and consider a large
#### dynamic factor model.









## 3 Machine/Deep Learning models and extension

### 3.1 Now consider machine learning benchmarks, such as those in the set of benchmarks or that
### are available on the M5 github (e.g. LSTM, using keras in R) and compare their performance
### in terms of point/probabilistic forecasts.




### 3.2 Can combinations of ML/DL techniques with standard techniques help?